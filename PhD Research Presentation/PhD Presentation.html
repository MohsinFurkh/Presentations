<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PhD Research Presentation - Medical Image Analysis</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            overflow: hidden;
        }

        .presentation-container {
            width: 100vw;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }

        .slide {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: white;
            padding: 60px 8% 50px; /* Adjusted padding for better space usage */
            display: none;
            overflow-y: auto;
            box-sizing: border-box;
            flex-direction: column;
            align-items: center;
            transition: opacity 0.5s ease-in-out, transform 0.5s ease-in-out;
            opacity: 0;
            transform: translateY(20px);
        }
        
        .slide.active {
            display: flex;
            opacity: 1;
            transform: translateY(0);
        }
        
        .slide-footer {
            position: absolute;
            bottom: 10px;
            left: 0;
            right: 0;
            text-align: center;
            font-size: 14px;
            color: #666;
            padding: 10px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: rgba(255, 255, 255, 0.9);
        }
        
        .slide-number {
            position: absolute;
            top: 10px;
            right: 20px;
            background: #667eea;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 14px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            z-index: 100;
        }
        
        .timer {
            position: fixed;
            top: 15px;
            left: 20px;
            background: #764ba2;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 500;
            z-index: 100;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        
        /* Thumbnails removed as requested */

        .slide.active {
            display: flex;
            animation: slideIn 0.6s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .slide h1 {
            font-size: 4rem; /* Increased from 3.5rem */
            font-weight: 700;
            margin: 0 0 20px 0;
            padding: 0 0 15px 0;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
            text-align: center;
            width: 100%;
            border-bottom: 2px solid #f0f0f0;
        }

        .slide h2 {
            color: #2c3e50;
            margin: 0 0 25px 0;
            font-size: 2.5rem; /* Increased from 2rem */
            font-weight: 700;
            position: relative;
            padding: 0 0 15px 0;
            text-align: center;
            width: 100%;
            max-width: 90%;
            align-self: center;
            border-bottom: 2px solid #f0f0f0;
        }

        .slide h3 {
            font-size: 2rem; /* Increased from 1.8rem */
            font-weight: 600;
            margin: 20px 0 15px 0;
            color: #34495e;
            width: 100%;
            max-width: 90%;
        }

        .slide p, .slide li {
            font-size: 1.4rem; /* Increased from 1rem */
            line-height: 1.7;
            color: #333;
            margin: 0 0 15px 0;
            width: 100%;
            max-width: 90%;
        }
        
        .slide ul, .slide ol {
            width: 100%;
            max-width: 90%;
            margin: 0 0 20px 0;
            padding-left: 30px;
        }
        
        .slide li {
            margin-bottom: 10px;
        }
        
        /* Table of Contents Styles */
        .toc-container {
            width: 100%;
            max-width: 1200px;
            margin: 20px auto 0;
            padding: 0 20px;
        }
        
        .toc-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }
        
        .toc-item {
            display: flex;
            background: #f8f9ff;
            border-radius: 10px;
            padding: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
            border-left: 4px solid #667eea;
            box-shadow: 0 3px 10px rgba(0,0,0,0.05);
            height: 100%;
            align-items: center;
        }
        
        .toc-item:hover {
            transform: translateY(-3px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.2);
            background: #f0f3ff;
        }
        
        .toc-number {
            font-size: 2rem;
            font-weight: bold;
            color: #667eea;
            min-width: 50px;
            height: 50px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 20px;
            background: rgba(102, 126, 234, 0.1);
            border-radius: 50%;
            flex-shrink: 0;
        }
        
        .toc-content h3 {
            margin: 0 0 5px 0;
            color: #2c3e50;
            font-size: 1.5rem;
            font-weight: 600;
        }
        
        .toc-content p {
            margin: 0;
            color: #666;
            font-size: 1.1rem;
            line-height: 1.5;
        }
        
        .toc-note {
            text-align: center;
            margin-top: 30px;
            font-size: 1.1rem;
            color: #667eea;
            font-style: italic;
        }
        
        @media (max-width: 768px) {
            .toc-grid {
                grid-template-columns: 1fr;
            }
            
            .toc-item {
                padding: 15px;
            }
            
            .toc-number {
                font-size: 1.6rem;
                min-width: 40px;
                height: 40px;
                margin-right: 15px;
            }
            
            .toc-content h3 {
                font-size: 1.3rem;
            }
            
            .toc-content p {
                font-size: 1rem;
            }
        }

        .slide ul, .slide ol {
            padding-left: 20px;
            margin: 10px 0;
        }

        .slide li {
            margin-bottom: 8px;
            position: relative;
        }

        .slide li::marker {
            color: #667eea;
            font-weight: bold;
        }

        .highlight-box {
            background: linear-gradient(135deg, #667eea15, #764ba215);
            border-left: 5px solid #667eea;
            padding: 30px 35px;
            margin: 35px auto;
            border-radius: 10px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.08);
            max-width: 85%;
            min-height: 120px;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }
        .highlight-box h3 {
            color: #4a5568;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 1.4em;
        }
        .highlight-box p {
            color: #2d3748;
            font-size: 1.1em;
            line-height: 1.6;
            margin: 0;
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            width: 100%;
            max-width: 1600px;
            margin: 10px 0 30px 0;
            align-self: center;
        }

        .three-column {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            width: 100%;
            max-width: 1600px;
            margin: 10px 0 30px 0;
            align-self: center;
        }

        .method-card {
            background: white;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.08);
            border-top: 4px solid #667eea;
            transition: transform 0.3s ease;
            height: 100%;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
        }

        .method-card:hover {
            transform: translateY(-5px);
        }

        .method-card h4 {
            font-size: 1.5rem;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 15px;
        }

        .metrics {
            display: flex;
            justify-content: space-around;
            margin: 30px 0;
        }

        .metric {
            text-align: center;
            padding: 20px;
            background: white;
            border-radius: 15px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            min-width: 150px;
        }

        .metric-value {
            font-size: 2.5rem;
            font-weight: bold;
            color: #667eea;
        }

        .metric-label {
            font-size: 1.1rem;
            color: #666;
            margin-top: 8px;
        }

        .navigation {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            display: flex;
            justify-content: space-between;
            padding: 15px 5%;
            z-index: 1000;
            background: white;
            box-shadow: 0 -2px 15px rgba(0, 0, 0, 0.08);
            max-width: 100%;
        }

        .nav-btn {
            pointer-events: auto;
            padding: 10px 24px;
            font-size: 0.95rem;
            background: #667eea;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 8px;
            font-weight: 500;
        }

        .nav-btn:hover {
            background: #667eea;
            color: white;
            transform: translateY(-2px);
        }

        .nav-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .slide-counter {
            position: fixed;
            top: 30px;
            right: 30px;
            background: rgba(255, 255, 255, 0.9);
            padding: 10px 20px;
            border-radius: 20px;
            font-weight: 600;
            color: #667eea;
            backdrop-filter: blur(10px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .subtitle {
            font-size: 1.8rem;
            color: #666;
            text-align: center;
            margin-bottom: 40px;
            font-weight: 300;
        }

        .author-info {
            text-align: center;
            margin-top: 40px;
            font-size: 1.4rem;
            color: #555;
        }

        .impact-stats {
            background: linear-gradient(135deg, #667eea10, #764ba210);
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
        }

        .research-timeline {
            position: relative;
            margin: 40px 0;
        }

        .timeline-item {
            display: flex;
            align-items: center;
            margin: 20px 0;
            padding: 20px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);
            border-left: 4px solid #667eea;
        }

        .timeline-number {
            background: #667eea;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 20px;
            font-weight: bold;
        }

        @media (max-width: 768px) {
            .slide {
                padding: 30px 20px;
                width: 95%;
            }
            
            .slide h1 {
                font-size: 2.5rem;
            }
            
            .slide h2 {
                font-size: 2rem;
            }
            
            .two-column, .three-column {
                grid-template-columns: 1fr;
                gap: 20px;
            }
            
            .metrics {
                flex-direction: column;
                gap: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="presentation-container">
        <div class="timer" id="presentationTimer">00:00</div>
        <div class="slide-number" id="currentSlideNumber">1</div>

        <!-- Slide 1: Title -->
        <div class="slide active" style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; height: 100%; padding: 40px 20px;">
            <div style="margin-bottom: 50px;">
                <h1 style="font-size: 3.2rem; margin-bottom: 20px; color: #2c3e50; line-height: 1.1; font-weight: 700;">PhD Research Presentation</h1>
                <p class="subtitle" style="font-size: 2rem; color: #4a6cf7; font-weight: 500; margin: 0 auto; max-width: 1000px; line-height: 1.3;">
                    Advances in Deep Learning for Medical Image<br>Segmentation and Classification
                </p>
            </div>
            
            <div class="author-info" style="background: rgba(255, 255, 255, 0.05); padding: 40px; border-radius: 10px; margin: 30px 0; width: 90%; max-width: 1000px;">
                <div style="font-size: 2.5rem; font-weight: 600; color: #2c3e50; margin-bottom: 10px;">Mohsin Furkh Dar</div>
                <div style="font-size: 1.6rem; color: #4a6cf7; margin-bottom: 30px; line-height: 1.4;">
                    School of Computer and Information Sciences<br>
                    University of Hyderabad
                </div>
                
                <div style="margin-top: 40px; max-width: 800px; margin: 40px auto 0; text-align: center;">
                    <img src="hcu.png" alt="University of Hyderabad Logo" style="max-width: 400px; height: auto; margin-bottom: 20px;">
                    <div id="currentDate" style="font-style: italic; color: #6c757d; margin-top: 10px; font-size: 1.3rem;"></div>
                    <script>
                        const options = { year: 'numeric', month: 'long', day: 'numeric' };
                        document.getElementById('currentDate').textContent = new Date().toLocaleDateString('en-US', options);
                    </script>
                </div>
            </div>
        </div>

        <!-- Slide 2: Table of Contents -->
        <div class="slide">
            <h1>Table of Contents</h1>
            <div class="toc-container">
                <div class="toc-grid">
                    <div class="toc-item" onclick="showSlide(2)">
                        <div class="toc-number">1</div>
                        <div class="toc-content">
                            <h3>Research Overview</h3>
                            <p>Key areas and technical expertise</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(3)">
                        <div class="toc-number">2</div>
                        <div class="toc-content">
                            <h3>EfficientU-Net</h3>
                            <p>Parameter-efficient medical segmentation</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(8)">
                        <div class="toc-number">3</div>
                        <div class="toc-content">
                            <h3>UMA-Net</h3>
                            <p>Multi-scale adaptive network</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(16)">
                        <div class="toc-number">4</div>
                        <div class="toc-content">
                            <h3>FRS Loss</h3>
                            <p>Fuzzy Rough Set Loss for Deep Learning-Based Precise Medical Image Segmentation</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(24)">
                        <div class="toc-number">5</div>
                        <div class="toc-content">
                            <h3>SGAN</h3>
                            <p>Saliency-guided attention network</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(30)">
                        <div class="toc-number">6</div>
                        <div class="toc-content">
                            <h3>Conclusions</h3>
                            <p>Summary and future directions</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(31)">
                        <div class="toc-number">7</div>
                        <div class="toc-content">
                            <h3>Published Work</h3>
                            <p>Research publications and contributions</p>
                        </div>
                    </div>
                    <div class="toc-item" onclick="showSlide(32)">
                        <div class="toc-number">8</div>
                        <div class="toc-content">
                            <h3>Teaching Experience</h3>
                            <p>Academic teaching and mentorship</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 3: Research Overview -->
        <div class="slide">
            <h2>Research Overview & Impact</h2>
            <div class="two-column">
                <div>
                    <h3>Key Research Areas</h3>
                    <ul>
                        <li><strong>Advanced Segmentation Architectures</strong> - EfficientU-Net & UMA-Net</li>
                        <li><strong>Novel Loss Function Development</strong> - Fuzzy Rough Set (FRS) Loss</li>
                        <li><strong>Multi-Modal Classification Systems</strong> - Saliency-Guided AttentionNet</li>
                        <li><strong>Optimization & Feature Selection</strong> - Ensemble with Genetic Algorithm</li>
                    </ul>
                </div>
                <div>
                    <h3>Technical Expertise</h3>
                    <ul>
                        <li>Convolutional Neural Networks</li>
                        <li>Attention Mechanisms</li>
                        <li>Transfer Learning</li>
                        <li>Multi-objective Optimization</li>
                        <li>Medical Imaging Modalities (Ultrasound, MRI, CT)</li>
                    </ul>
                </div>
            </div>
            <div class="impact-stats">
                <h3>Clinical Impact</h3>
                <p>Achieved state-of-the-art results while maintaining computational efficiency suitable for clinical deployment across multiple medical imaging tasks and datasets.</p>
            </div>
        </div>

        <!-- Slide 4: EfficientU-Net -->
        <div class="slide">
            <h2>EfficientU-Net: Parameter-Efficient Medical Segmentation</h2>
            <div class="highlight-box">
                <h3>Problem Addressed</h3>
                <p>Standard U-Net suffers from information loss, irrelevant feature capture, poor boundary localization, and high computational cost.</p>
            </div>
            
            <div class="two-column">
                <div>
                    <h3>Key Innovations</h3>
                    <ul>
                        <li><strong>Depthwise Separable Convolutions</strong> - 100× fewer multiplications than regular convolution</li>
                        <li><strong>Atrous Convolution (AC) Blocks</strong> - Adaptive receptive fields for varying tumor shapes</li>
                        <li><strong>Compound Scaling Method</strong> - Balanced scaling across width, depth, and resolution</li>
                    </ul>
                </div>
                <div>
                    <h3>Technical Advantages</h3>
                    <ul>
                        <li>Significant parameter reduction</li>
                        <li>Reduced FLOPS cost</li>
                        <li>Improved boundary localization</li>
                        <li>Better handling of multi-scale features</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 5: EfficientU-Net Architecture Overview -->
        <div class="slide">
            <h2>EfficientU-Net: Architecture Overview</h2>
            <div class="two-column" style="align-items: flex-start;">
                <div style="display: flex; flex-direction: column; height: 100%;">
                    <h3 style="text-align: center;">Standard U-Net Baseline</h3>
                    <div style="flex: 1; display: flex; justify-content: center; align-items: center; background: #f8f9fa; border-radius: 10px; padding: 10px; box-shadow: 0 5px 15px rgba(0,0,0,0.1);">
                        <img src="Model_Figures/EfficientU-Net/unet_arch.png" alt="Standard U-Net Architecture" style="max-width: 100%; max-height: 500px; width: auto; height: auto; object-fit: contain; border-radius: 5px;">
                    </div>
                    <p class="caption" style="text-align: center; margin-top: 10px;">Standard U-Net Architecture<sup>1</sup></p>
                </div>
                <div style="display: flex; flex-direction: column; height: 100%;">
                    <h3 style="text-align: center;">Proposed EfficientU-Net</h3>
                    <div style="flex: 1; display: flex; justify-content: center; align-items: center; background: #f8f9fa; border-radius: 10px; padding: 10px; box-shadow: 0 5px 15px rgba(0,0,0,0.1);">
                        <img src="Model_Figures/EfficientU-Net/Full_EfficientU-Net.jpg" alt="EfficientU-Net Architecture" style="max-width: 100%; max-height: 500px; width: auto; height: auto; object-fit: contain; border-radius: 5px;">
                    </div>
                    <p class="caption" style="text-align: center; margin-top: 10px;">Our EfficientU-Net Architecture<sup>2</sup></p>
                </div>
            </div>            
            <div style="margin-top: 20px; font-size: 0.8rem; color: #555; text-align: left; max-width: 90%; margin-left: auto; margin-right: auto; padding: 15px; border-top: 2px solid #e0e0e0; background-color: #f9f9f9; border-radius: 0 0 10px 10px; line-height: 1.5; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
                <p style="margin: 8px 0; font-weight: 500; color: #444;">References:</p>
                <ol style="padding-left: 20px; margin: 10px 0 5px 0;">
                    <li style="margin-bottom: 10px;">Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015</em> (pp. 234–241). Springer. <a href="https://doi.org/10.1007/978-3-319-24574-4_28" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                    <li>Dar, M. F., & Ganivada, A. (2023). EfficientU-Net: A Novel Deep Learning Method for Breast Tumor Segmentation and Classification in Ultrasound Images. <em>Neural Processing Letters</em>. <a href="https://doi.org/10.1007/s11063-023-11333-x" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                </ol>
            </div>
        </div>

        <!-- Slide 6: EfficientU-Net Components -->
        <div class="slide">
            <h2>EfficientU-Net: Key Components</h2>
            <div style="display: flex; flex-direction: column; align-items: center; width: 90%; margin: 0 auto;">
                <div style="width: 100%; margin-bottom: 30px;">
                    <h3 style="text-align: center; margin-bottom: 10px;">Encoder Architecture</h3>
                    <div style="display: flex; justify-content: center;">
                        <img src="Model_Figures/EfficientU-Net/Encoder_EfficientU-Net.png" alt="EfficientU-Net Encoder" style="max-width: 90%; max-height: 60vh; border-radius: 10px; box-shadow: 0 5px 15px rgba(0,0,0,0.1);">
                    </div>
                    <p class="caption" style="text-align: center; margin-top: 10px;">Efficient Encoder with Depthwise Separable Convolutions<sup>1</sup></p>
                </div>
                <div style="width: 100%;">
                    <h3 style="text-align: center; margin-bottom: 10px;">Atrous Convolution Block</h3>
                    <div style="display: flex; justify-content: center;">
                        <img src="Model_Figures/EfficientU-Net/AC_Block_EfficientU_Net.png" alt="Atrous Convolution Block" style="max-width: 90%; max-height: 60vh; border-radius: 10px; box-shadow: 0 5px 15px rgba(0,0,0,0.1);">
                    </div>
                    <p class="caption" style="text-align: center; margin-top: 10px;">Atrous Convolution Block for Multi-scale Feature Extraction<sup>1</sup></p>
                </div>
            </div>
            <div style="margin-top: 30px; font-size: 0.8rem; color: #555; text-align: left; max-width: 90%; margin-left: auto; margin-right: auto; padding: 15px; border-top: 2px solid #e0e0e0; background-color: #f9f9f9; border-radius: 0 0 10px 10px; line-height: 1.5; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
                <p style="margin: 0; font-weight: 500; color: #444;">Reference:</p>
                <p style="margin: 8px 0 0 0;">Dar, M. F., & Ganivada, A. (2023). EfficientU-Net: A Novel Deep Learning Method for Breast Tumor Segmentation and Classification in Ultrasound Images. <em>Neural Processing Letters</em>. <a href="https://doi.org/10.1007/s11063-023-11333-x" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></p>
            </div>
        </div>

         <!-- Slide 7: EfficientU-Net Quantitative Analysis -->
         <div class="slide">
            <h2>EfficientU-Net: Quantitative Analysis</h2>
            <style>
                .tables-vertical {
                    display: flex;
                    flex-direction: column;
                    gap: 30px;
                    max-width: 95%;
                    margin: 0 auto;
                }
                .table-container {
                    margin-bottom: 20px;
                    overflow-x: auto;
                    border-radius: 12px;
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                    background: white;
                    padding: 10px;
                }
                .table-container table {
                    width: 100%;
                    border-collapse: collapse;
                    font-size: 14px;  /* Increased from 12px */
                    margin: 0 auto;
                }
                .table-container th, .table-container td {
                    padding: 12px 10px;  /* Increased padding */
                    text-align: center;
                    border: 1px solid #e0e0e0;
                    vertical-align: middle;
                    font-size: 13px;  /* Added for consistency */
                }
                .table-container th {
                    background: linear-gradient(135deg, #667eea, #764ba2);
                    color: white;
                    font-weight: 600;
                    text-transform: uppercase;
                    letter-spacing: 0.5px;
                    font-size: 12px;  /* Slightly increased */
                    padding: 14px 10px;  /* Increased padding */
                }
                .table-container .main-header {
                    background: linear-gradient(135deg, #4a5568, #2d3748);
                }
                .table-container .sub-header {
                    background: linear-gradient(135deg, #667eea, #764ba2);
                    opacity: 0.9;
                    font-size: 11px;  /* Slightly increased */
                }
                .table-container tr:nth-child(even) {
                    background-color: #f8fafc;
                }
                .table-container tr:hover {
                    background-color: #e2e8f0;
                }
                .table-container .best-value {
                    font-weight: bold;
                    color: #2563eb;
                    background-color: #dbeafe;
                    border-radius: 4px;
                    padding: 4px 6px;
                    font-size: 13px;  /* Match cell font size */
                }
                .table-container .network-name {
                    text-align: left;
                    font-weight: 600;
                    color: #1e293b;
                    font-size: 13px;  /* Match cell font size */
                }
                .table-container .proposed-method {
                    background-color: #fef3c7;
                    font-weight: bold;
                }
                .table-container .proposed-method td {
                    background-color: #fef3c7;
                }
                .table-container .std-dev {
                    font-size: 11px;  /* Slightly increased */
                    color: #64748b;
                    display: block;
                    margin-top: 3px;  /* Slightly increased */
                }
                .table-caption {
                    text-align: center;
                    margin-top: 12px;
                    font-style: italic;
                    color: #64748b;
                    font-size: 14px;  /* Increased from 12px */
                }
                .table-title {
                    font-size: 20px;  /* Increased from 16px */
                    font-weight: 600;
                    color: #1e293b;
                    margin: 15px 0;
                    text-align: center;
                }
            </style>
            
            <div class="tables-vertical">
                <!-- Table 1: Main Comparison -->
                <div class="table-section">
                    <h3 class="table-title">Comparison with State-of-the-Art</h3>
                    <div class="table-container">
                        <table>
                            <thead>
                                <tr class="main-header">
                                    <th rowspan="2">Networks</th>
                                    <th rowspan="2">Params<br>(in M)</th>
                                    <th rowspan="2">Speed<br>(s)</th>
                                    <th rowspan="2">GFLOPs</th>
                                    <th colspan="2" class="sub-header">BUSI</th>
                                    <th colspan="2" class="sub-header">Dataset B</th>
                                </tr>
                                <tr class="sub-header">
                                    <th>Dice</th>
                                    <th>IoU</th>
                                    <th>Dice</th>
                                    <th>IoU</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="network-name">U-Net (Ronneberger et al. 2015) </td>
                                    <td>9.34</td>
                                    <td>1.67</td>
                                    <td>70.6</td>
                                    <td>0.8880<span class="std-dev">(±0.016)</span></td>
                                    <td>0.7989<span class="std-dev">(±0.026)</span></td>
                                    <td>0.8148<span class="std-dev">(±0.099)</span></td>
                                    <td>0.6961<span class="std-dev">(±0.128)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">U-Net++ (Zhou et al. 2018)</td>
                                    <td>9.68</td>
                                    <td>1.54</td>
                                    <td>98.4</td>
                                    <td>0.8961<span class="std-dev">(±0.003)</span></td>
                                    <td>0.8119<span class="std-dev">(±0.005)</span></td>
                                    <td>0.8880<span class="std-dev">(±0.016)</span></td>
                                    <td>0.7989<span class="std-dev">(±0.026)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">AttentionU-Net (Oktay et al.2018)</td>
                                    <td>8.65</td>
                                    <td>1.60</td>
                                    <td>60.7</td>
                                    <td>0.8933<span class="std-dev">(±0.007)</span></td>
                                    <td>0.8074<span class="std-dev">(±0.013)</span></td>
                                    <td>0.8317<span class="std-dev">(±0.108)</span></td>
                                    <td>0.7226<span class="std-dev">(±0.142)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">U-Net3+ (Huang et al. 2020)</td>
                                    <td>7.90</td>
                                    <td>1.68</td>
                                    <td>33.7</td>
                                    <td>0.8820<span class="std-dev">(±0.024)</span></td>
                                    <td>0.8132<span class="std-dev">(±0.072)</span></td>
                                    <td>0.8514<span class="std-dev">(±0.057)</span></td>
                                    <td>0.7991<span class="std-dev">(±0.025)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">U2-Net (Qin et al. 2020)</td>
                                    <td>52.94</td>
                                    <td>1.79</td>
                                    <td>22.0</td>
                                    <td>0.9015<span class="std-dev">(±0.023)</span></td>
                                    <td>0.8204<span class="std-dev">(±0.032)</span></td>
                                    <td>0.9102<span class="std-dev">(±0.058)</span></td>
                                    <td>0.8381<span class="std-dev">(±0.165)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">TransU-Net (Chen et al. 2021)</td>
                                    <td>407</td>
                                    <td>1.93</td>
                                    <td>54.6</td>
                                    <td class="best-value">0.9103<span class="std-dev">(±0.054)</span></td>
                                    <td class="best-value">0.8342<span class="std-dev">(±0.052)</span></td>
                                    <td>0.9189<span class="std-dev">(±0.138)</span></td>
                                    <td>0.8433<span class="std-dev">(±0.119)</span></td>
                                </tr>
                                <tr class="proposed-method">
                                    <td class="network-name">Proposed EfficientU-Net</td>
                                    <td class="best-value">5.76</td>
                                    <td class="best-value">1.47</td>
                                    <td class="best-value">19.35</td>
                                    <td>0.9045<span class="std-dev">(±0.007)</span></td>
                                    <td>0.8258<span class="std-dev">(±0.012)</span></td>
                                    <td class="best-value">0.9227<span class="std-dev">(±0.011)</span></td>
                                    <td class="best-value">0.8567<span class="std-dev">(±0.020)</span></td>
                                </tr>
                            </tbody>
                        </table>
                        <p class="table-caption">Table 1: Segmentation results of the proposed EfficientU-Net comparing with the recently published methods</p>
                    </div>
                </div>
                
                <!-- Table 2: Ablation Study -->
                <div class="table-section">
                    <h3 class="table-title">Ablation Study Results</h3>
                    <div class="table-container">
                        <table>
                            <thead>
                                <tr class="main-header">
                                    <th>Network</th>
                                    <th>Params<br>(in M)</th>
                                    <th>GFLOPs<br>(in G)</th>
                                    <th>Inf. Time<br>(s)</th>
                                    <th>Dice</th>
                                    <th>IoU</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="network-name">U-Net</td>
                                    <td>9.34</td>
                                    <td>70.6</td>
                                    <td>1.67</td>
                                    <td>0.8880<span class="std-dev">(±0.016)</span></td>
                                    <td>0.7989<span class="std-dev">(±0.026)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">EfficientU-Net<br>without AC block</td>
                                    <td>5.73</td>
                                    <td>16.7</td>
                                    <td>1.44</td>
                                    <td>0.8947<span class="std-dev">(±0.014)</span></td>
                                    <td>0.8033<span class="std-dev">(±0.008)</span></td>
                                </tr>
                                <tr>
                                    <td class="network-name">EfficientU-Net<br>with ASPP</td>
                                    <td>6.31</td>
                                    <td>24.1</td>
                                    <td>1.52</td>
                                    <td>0.8991<span class="std-dev">(±0.034)</span></td>
                                    <td>0.8122<span class="std-dev">(±0.022)</span></td>
                                </tr>
                                <tr class="proposed-method">
                                    <td class="network-name">EfficientU-Net<br>with AC block</td>
                                    <td>5.76</td>
                                    <td>19.35</td>
                                    <td>1.47</td>
                                    <td class="best-value">0.9045<span class="std-dev">(±0.007)</span></td>
                                    <td class="best-value">0.8258<span class="std-dev">(±0.012)</span></td>
                                </tr>
                            </tbody>
                        </table>
                        <p class="table-caption">Table 2: Results of the ablation study</p>
                    </div>
                </div>
            </div>
            <div style="margin-top: 30px; font-size: 0.8rem; color: #555; text-align: left; max-width: 90%; margin-left: auto; margin-right: auto; padding: 15px; border-top: 2px solid #e0e0e0; background-color: #f9f9f9; border-radius: 0 0 10px 10px; line-height: 1.5; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
                <p style="margin: 0 0 10px 0; font-weight: 500; color: #444;">References:</p>
                <ol style="padding-left: 20px; margin: 0;">
                    <li style="margin-bottom: 8px;">Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015</em> (pp. 234–241). Springer.</li>
                    <li style="margin-bottom: 8px;">Zhou, Z., Rahman Siddiquee, M. M., Tajbakhsh, N., & Liang, J. (2018). UNet++: A Nested U-Net Architecture for Medical Image Segmentation. In <em>Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support</em> (pp. 3-11). Springer.</li>
                    <li style="margin-bottom: 8px;">Oktay, O., Schlemper, J., Folgoc, L. L., Lee, M., Heinrich, M., Misawa, K., ... & Rueckert, D. (2018). Attention U-Net: Learning Where to Look for the Pancreas. <em>arXiv preprint arXiv:1804.03999</em>.</li>
                    <li style="margin-bottom: 8px;">Huang, H., Lin, L., Tong, R., Hu, H., Zhang, Q., Iwamoto, Y., ... & Wu, J. (2020). UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation. In <em>ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> (pp. 1055-1059). IEEE.</li>
                    <li style="margin-bottom: 8px;">Qin, X., Zhang, Z., Huang, C., Dehghan, M., Zaiane, O. R., & Jagersand, M. (2020). U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection. <em>Pattern Recognition</em>, 106, 107404.</li>
                    <li style="margin-bottom: 8px;">Chen, J., Lu, Y., Yu, Q., Luo, X., Adeli, E., Wang, Y., ... & Zhou, Y. (2021). TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation. <em>arXiv preprint arXiv:2102.04306</em>.</li>
                    <li>Dar, M. F., & Ganivada, A. (2023). EfficientU-Net: A Novel Deep Learning Method for Breast Tumor Segmentation and Classification in Ultrasound Images. <em>Neural Processing Letters</em>.</li>
                </ol>
            </div>
        </div>

        <!-- Slide 8: EfficientU-Net Results -->
        <div class="slide">
            <h2>EfficientU-Net: Results</h2>
            <div class="two-column">
                <div>
                    <h3>Segmentation Performance</h3>
                    <div style="margin-bottom: 20px;">
                        <img src="Results/EfficientU-Net/Box_Plot_IoU.png" alt="IoU Comparison" style="width: 100%; border-radius: 8px; margin-bottom: 5px;">
                        <img src="Results/EfficientU-Net/Box_plot_Dice.png" alt="Dice Score Comparison" style="width: 100%; border-radius: 8px; margin-bottom: 5px;">
                        <p class="caption">Boxplots of Dice and IoU scores for combined test samples of BUSI and UDIAT datasets. Boxes indicate score ranges, the color line represents the median, and dots show outliers.</p>
                    </div>
                    <div>
                        <img src="Results/EfficientU-Net/Learning Curves.png" alt="Training Curves" style="width: 100%; border-radius: 8px; margin-bottom: 5px;">
                        <p class="caption">Training progress on BUSI dataset: Dice coefficient (left) and dice loss (right) for validation compared with UNet, UNet++, and Attention UNet.</p>
                    </div>
                </div>
                <div>
                    <h3>Qualitative Results</h3>
                    <div style="margin-bottom: 15px;">
                        <img src="Results/EfficientU-Net/Benign Segmentation Results.jpg" alt="Benign Results" style="width: 100%; border-radius: 8px; margin-bottom: 5px;">
                        <p class="caption" style="margin-bottom: 15px;">Segmentation results for benign breast ultrasound images from BUSI dataset.</p>
                    </div>
                    <div class="vertical-stack">
                        <div class="stacked-image">
                            <img src="Results/EfficientU-Net/Malignant_Segmentation Results.jpg" alt="Malignant Results" style="width: 100%; border-radius: 8px; margin-bottom: 5px;">
                            <p class="caption">Malignant case segmentation</p>
                        </div>
                        <div class="stacked-image">
                            <img src="Results/EfficientU-Net/Norma_Segmentation Results.jpg" alt="Normal Results" style="width: 100%; border-radius: 8px; margin-bottom: 5px;">
                            <p class="caption">Normal case segmentation</p>
                        </div>
                    </div>
                    <style>
                        .vertical-stack {
                            display: flex;
                            flex-direction: column;
                            gap: 15px;
                            width: 100%;
                        }
                        .stacked-image {
                            width: 100%;
                        }
                        @media (min-width: 768px) {
                            .vertical-stack {
                                width: 100%;
                            }
                            .stacked-image {
                                width: 100%;
                            }
                        }
                    </style>
                </div>
            </div>
        </div>


        <!-- Slide 9: UMA-Net -->
        <div class="slide">
            <h2>UMA-Net: Multi-Scale Adaptive Network</h2>
            <div class="highlight-box">
                <h3>Motivation</h3>
                <p>Enhanced EfficientU-Net to address generalizability challenges across diverse datasets with varying scale and frequency characteristics.</p>
            </div>
            
            <div class="three-column">
                <div class="method-card">
                    <h4>Architectural Enhancements</h4>
                    <ul>
                        <li>MobileNet backbone encoder</li>
                        <li>Residual connections</li>
                        <li>Attention mechanisms</li>
                        <li>Four-stage feature extraction</li>
                    </ul>
                </div>
                <div class="method-card">
                    <h4>Attention Integration</h4>
                    <ul>
                        <li>Attention gates in decoder</li>
                        <li>Spatial detail preservation</li>
                        <li>Contextual guidance</li>
                        <li>Relevant region emphasis</li>
                    </ul>
                </div>
                <div class="method-card">
                    <h4>Adaptive Loss Function</h4>
                    <ul>
                        <li>Dynamic weight adjustment</li>
                        <li>BCE + Dice + Hausdorff + Tversky</li>
                        <li>Balanced optimization</li>
                        <li>Performance-based weighting</li>
                    </ul>
                </div>
            </div>
        </div>


        <!-- Slide 10: UMA-Net Workflow -->
        <div class="slide">
            <h2>UMA-Net: Workflow</h2>
            <div class="image-container" style="max-width: 80%; margin: 0 auto;">
                <img src="Model_Figures/UMA-Net/WorkFlow.jpg" alt="UMA-Net Workflow" style="width: 100%; border-radius: 8px;">
                <p class="caption">Workflow of the proposed UMA-Net model for breast tumor segmentation<sup>1</sup></p>
            </div>
            
            <div style="margin-top: 30px; font-size: 0.8rem; color: #555; text-align: left; max-width: 90%; margin-left: auto; margin-right: auto; padding: 15px; border-top: 2px solid #e0e0e0; background-color: #f9f9f9; border-radius: 0 0 10px 10px; line-height: 1.5; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
                <p style="margin: 0; font-weight: 500; color: #444;">Reference:</p>
                <p style="margin: 8px 0 0 0;">Dar, M. F., & Ganivada, A. (2023). UMA-Net: A Novel Deep Learning Approach for Enhanced Breast Tumor Segmentation in Ultrasound Images. <em>Neural Processing Letters</em>. <a href="https://doi.org/10.1007/s11063-023-11333-x" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></p>
            </div>
        </div>


        <!-- Slide 11: UMA-Net Architecture Components -->
        <div class="slide">
            <h2>UMA-Net: Key Components</h2>
            <div style="display: flex; gap: 20px; margin-top: 20px;">
                <div style="flex: 1;">
                    <div style="height: 350px; display: flex; align-items: center; justify-content: center; background: #f8f9fa; border-radius: 8px; margin-bottom: 10px;">
                        <img src="Model_Figures/UMA-Net/Attention Block.png" alt="Attention Block" style="max-width: 100%; max-height: 100%; width: auto; height: auto; object-fit: contain; border-radius: 4px;">
                    </div>
                    <p class="caption">Attention block applied in the decoder of UMA-Net</p>
                </div>
                <div style="flex: 1;">
                    <div style="height: 350px; display: flex; align-items: center; justify-content: center; background: #f8f9fa; border-radius: 8px; margin-bottom: 10px;">
                        <img src="Model_Figures/UMA-Net/ResBlock.png" alt="Residual Block" style="max-width: 100%; max-height: 100%; width: auto; height: auto; object-fit: contain; border-radius: 4px;">
                    </div>
                    <p class="caption">Residual block refines the combined features</p>
                </div>
            </div>
        </div>

        <!-- Slide 12: UMA-Net Training Progress -->
        <div class="slide">
            <h2>UMA-Net: Training Progress</h2>
            <div style="display: flex; gap: 20px; margin-top: 20px;">
                <div style="flex: 1;">
                    <img src="Results/UMA-Net/Fig6a.png" alt="Training Loss" style="width: 100%; border-radius: 8px;">
                    <p class="caption">Training and validation loss curves</p>
                </div>
                <div style="flex: 1;">
                    <img src="Results/UMA-Net/Fig6b.png" alt="Dice Coefficient" style="width: 100%; border-radius: 8px;">
                    <p class="caption">Training and validation Dice coefficient</p>
                </div>
            </div>
        </div>

        <!-- Slide 13: UMA-Net Quantitative Comparison -->
        <div class="slide">
            <h2>UMA-Net: Quantitative Comparison</h2>
            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>Dice</th>
                            <th>IoU</th>
                            <th>Sensitivity</th>
                            <th>Specificity</th>
                            <th>Accuracy</th>
                        </tr>
                    </thead>
                    <tbody>
                        <!-- BUSI Dataset -->
                        <tr class="dataset-header">
                            <td colspan="6">BUSI</td>
                        </tr>
                        <tr>
                            <td class="model-name">U-Net (Ronneberger et al., 2015)</td>
                            <td>0.641<span class="std-dev">±0.02</span></td>
                            <td>0.472<span class="std-dev">±0.02</span></td>
                            <td>0.511<span class="std-dev">±0.09</span></td>
                            <td>0.991<span class="std-dev">±0.04</span></td>
                            <td>0.946<span class="std-dev">±0.06</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">Attention U-Net (Oktay et al., 2018)</td>
                            <td>0.692<span class="std-dev">±0.03</span></td>
                            <td>0.529<span class="std-dev">±0.01</span></td>
                            <td>0.557<span class="std-dev">±0.14</span></td>
                            <td class="best-value">0.994<span class="std-dev">±0.07</span></td>
                            <td>0.953<span class="std-dev">±0.12</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">V-Net (Milletari et al., 2016)</td>
                            <td>0.680<span class="std-dev">±0.02</span></td>
                            <td>0.516<span class="std-dev">±0.00</span></td>
                            <td class="best-value">0.830<span class="std-dev">±0.05</span></td>
                            <td>0.937<span class="std-dev">±0.04</span></td>
                            <td>0.927<span class="std-dev">±0.09</span></td>
                        </tr>
                        <tr class="uma-net-row">
                            <td class="model-name">UMA-Net</td>
                            <td class="best-value">0.743<span class="std-dev">±0.05</span></td>
                            <td class="best-value">0.591<span class="std-dev">±0.02</span></td>
                            <td>0.659<span class="std-dev">±0.13</span></td>
                            <td>0.988<span class="std-dev">±0.08</span></td>
                            <td class="best-value">0.957<span class="std-dev">±0.08</span></td>
                        </tr>
    
                        <!-- UDIAT Dataset -->
                        <tr class="dataset-header">
                            <td colspan="6">UDIAT</td>
                        </tr>
                        <tr>
                            <td class="model-name">U-Net (Ronneberger et al., 2015)</td>
                            <td>0.761<span class="std-dev">±0.008</span></td>
                            <td>0.616<span class="std-dev">±0.016</span></td>
                            <td>0.672<span class="std-dev">±0.09</span></td>
                            <td>0.994<span class="std-dev">±0.04</span></td>
                            <td>0.979<span class="std-dev">±0.06</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">Attention U-Net (Oktay et al., 2018)</td>
                            <td>0.780<span class="std-dev">±0.03</span></td>
                            <td>0.653<span class="std-dev">±0.01</span></td>
                            <td>0.835<span class="std-dev">±0.14</span></td>
                            <td>0.986<span class="std-dev">±0.07</span></td>
                            <td>0.979<span class="std-dev">±0.12</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">V-Net (Milletari et al., 2016)</td>
                            <td>0.764<span class="std-dev">±0.02</span></td>
                            <td>0.671<span class="std-dev">±0.00</span></td>
                            <td class="best-value">0.921<span class="std-dev">±0.05</span></td>
                            <td>0.956<span class="std-dev">±0.04</span></td>
                            <td>0.897<span class="std-dev">±0.09</span></td>
                        </tr>
                        <tr class="uma-net-row">
                            <td class="model-name">UMA-Net</td>
                            <td class="best-value">0.818<span class="std-dev">±0.07</span></td>
                            <td class="best-value">0.692<span class="std-dev">±0.02</span></td>
                            <td>0.793<span class="std-dev">±0.13</span></td>
                            <td class="best-value">0.996<span class="std-dev">±0.08</span></td>
                            <td class="best-value">0.984<span class="std-dev">±0.08</span></td>
                        </tr>
    
                        <!-- OMI Dataset -->
                        <tr class="dataset-header">
                            <td colspan="6">OMI</td>
                        </tr>
                        <tr>
                            <td class="model-name">U-Net (Ronneberger et al., 2015)</td>
                            <td>0.656<span class="std-dev">±0.05</span></td>
                            <td>0.488<span class="std-dev">±0.02</span></td>
                            <td>0.810<span class="std-dev">±0.09</span></td>
                            <td>0.967<span class="std-dev">±0.04</span></td>
                            <td>0.960<span class="std-dev">±0.06</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">Attention U-Net (Oktay et al., 2018)</td>
                            <td>0.663<span class="std-dev">±0.04</span></td>
                            <td>0.496<span class="std-dev">±0.01</span></td>
                            <td>0.506<span class="std-dev">±0.14</span></td>
                            <td class="best-value">0.999<span class="std-dev">±0.07</span></td>
                            <td>0.976<span class="std-dev">±0.12</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">V-Net (Milletari et al., 2016)</td>
                            <td>0.738<span class="std-dev">±0.07</span></td>
                            <td>0.585<span class="std-dev">±0.02</span></td>
                            <td>0.609<span class="std-dev">±0.13</span></td>
                            <td>0.998<span class="std-dev">±0.08</span></td>
                            <td>0.979<span class="std-dev">±0.08</span></td>
                        </tr>
                        <tr class="uma-net-row">
                            <td class="model-name">UMA-Net</td>
                            <td class="best-value">0.790<span class="std-dev">±0.07</span></td>
                            <td class="best-value">0.653<span class="std-dev">±0.02</span></td>
                            <td class="best-value">0.835<span class="std-dev">±0.13</span></td>
                            <td>0.986<span class="std-dev">±0.08</span></td>
                            <td class="best-value">0.981<span class="std-dev">±0.08</span></td>
                        </tr>
    
                        <!-- Mendeley Dataset -->
                        <tr class="dataset-header">
                            <td colspan="6">Mendeley</td>
                        </tr>
                        <tr>
                            <td class="model-name">U-Net (Ronneberger et al., 2015)</td>
                            <td>0.786<span class="std-dev">±0.05</span></td>
                            <td>0.647<span class="std-dev">±0.02</span></td>
                            <td>0.666<span class="std-dev">±0.09</span></td>
                            <td class="best-value">0.994<span class="std-dev">±0.04</span></td>
                            <td>0.943<span class="std-dev">±0.06</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">Attention U-Net (Oktay et al., 2018)</td>
                            <td>0.872<span class="std-dev">±0.04</span></td>
                            <td>0.774<span class="std-dev">±0.01</span></td>
                            <td>0.847<span class="std-dev">±0.14</span></td>
                            <td>0.982<span class="std-dev">±0.07</span></td>
                            <td>0.961<span class="std-dev">±0.12</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">V-Net (Milletari et al., 2016)</td>
                            <td>0.868<span class="std-dev">±0.04</span></td>
                            <td>0.768<span class="std-dev">±0.01</span></td>
                            <td>0.812<span class="std-dev">±0.14</span></td>
                            <td>0.989<span class="std-dev">±0.07</span></td>
                            <td>0.962<span class="std-dev">±0.12</span></td>
                        </tr>
                        <tr class="uma-net-row">
                            <td class="model-name">UMA-Net</td>
                            <td class="best-value">0.884<span class="std-dev">±0.07</span></td>
                            <td class="best-value">0.788<span class="std-dev">±0.02</span></td>
                            <td class="best-value">0.892<span class="std-dev">±0.13</span></td>
                            <td>0.975<span class="std-dev">±0.08</span></td>
                            <td class="best-value">0.963<span class="std-dev">±0.08</span></td>
                        </tr>
    
                        <!-- BUET Dataset -->
                        <tr class="dataset-header">
                            <td colspan="6">BUET</td>
                        </tr>
                        <tr>
                            <td class="model-name">U-Net (Ronneberger et al., 2015)</td>
                            <td>0.731<span class="std-dev">±0.26</span></td>
                            <td>0.576<span class="std-dev">±0.224</span></td>
                            <td>0.597<span class="std-dev">±0.09</span></td>
                            <td class="best-value">0.993<span class="std-dev">±0.04</span></td>
                            <td>0.932<span class="std-dev">±0.06</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">Attention U-Net (Oktay et al., 2018)</td>
                            <td>0.740<span class="std-dev">±0.04</span></td>
                            <td>0.588<span class="std-dev">±0.01</span></td>
                            <td>0.621<span class="std-dev">±0.14</span></td>
                            <td>0.989<span class="std-dev">±0.07</span></td>
                            <td>0.933<span class="std-dev">±0.12</span></td>
                        </tr>
                        <tr>
                            <td class="model-name">V-Net (Milletari et al., 2016)</td>
                            <td>0.764<span class="std-dev">±0.05</span></td>
                            <td>0.619<span class="std-dev">±0.00</span></td>
                            <td>0.694<span class="std-dev">±0.05</span></td>
                            <td>0.978<span class="std-dev">±0.04</span></td>
                            <td>0.934<span class="std-dev">±0.09</span></td>
                        </tr>
                        <tr class="uma-net-row">
                            <td class="model-name">UMA-Net</td>
                            <td class="best-value">0.770<span class="std-dev">±0.07</span></td>
                            <td class="best-value">0.626<span class="std-dev">±0.02</span></td>
                            <td class="best-value">0.690<span class="std-dev">±0.13</span></td>
                            <td>0.981<span class="std-dev">±0.08</span></td>
                            <td class="best-value">0.936<span class="std-dev">±0.08</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
    
            <div class="caption">
                Table 3: Comparison of BUS image segmentation results (mean±standard deviation) of UMA-Net with SOTA segmentation models on five BUS image datasets by five-fold cross-validation.
            </div>
            
            <style>
                body {
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                    margin: 40px;
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    min-height: 100vh;
                    padding: 20px;
                }
        
                .container {
                    background: white;
                    border-radius: 16px;
                    padding: 40px;
                    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                    backdrop-filter: blur(10px);
                    max-width: 1200px;
                    margin: 0 auto;
                }
        
                .table-title {
                    font-size: 28px;
                    font-weight: 700;
                    color: #1e293b;
                    margin-bottom: 30px;
                    text-align: center;
                    background: linear-gradient(135deg, #667eea, #764ba2);
                    -webkit-background-clip: text;
                    -webkit-text-fill-color: transparent;
                    background-clip: text;
                }
        
                .table-container {
                    overflow-x: auto;
                    border-radius: 12px;
                    box-shadow: 0 8px 32px rgba(0,0,0,0.1);
                    margin-bottom: 30px;
                    /* Let the container expand to fit content */
                    height: auto;
                    min-height: 900px; /* Increased minimum height to fit all rows */
                    overflow-y: visible; /* Remove vertical scroll */
                }
        
                table {
                    width: 100%;
                    border-collapse: collapse;
                    background: white;
                    font-size: 14px;
                    border-radius: 12px;
                    overflow: hidden;
                    min-width: 800px;
                }
        
                th, td {
                    padding: 12px 16px;
                    text-align: center;
                    border: 1px solid #e0e0e0;
                    vertical-align: middle;
                }
        
                th {
                    background: linear-gradient(135deg, #667eea, #764ba2);
                    color: white;
                    font-weight: 600;
                    text-transform: uppercase;
                    letter-spacing: 0.5px;
                    font-size: 13px;
                }
        
                .dataset-header {
                    background: linear-gradient(135deg, #4a5568, #2d3748);
                    font-size: 16px;
                    font-weight: 700;
                    color: white;
                    text-transform: uppercase;
                    letter-spacing: 1px;
                }
        
                .model-name {
                    text-align: left;
                    font-weight: 600;
                    color: #1e293b;
                    background-color: #f8fafc;
                }
        
                .uma-net-row {
                    background-color: #fef3c7;
                    font-weight: 600;
                }
        
                .uma-net-row td {
                    background-color: #fef3c7;
                }
        
                .uma-net-row .model-name {
                    background-color: #fbbf24;
                    color: #92400e;
                }
        
                .best-value {
                    font-weight: bold;
                    color: #2563eb;
                    background-color: #dbeafe;
                    border-radius: 6px;
                    padding: 4px 8px;
                }
        
                tr:hover:not(.dataset-header) {
                    background-color: #e2e8f0;
                    transform: translateY(-1px);
                    transition: all 0.2s ease;
                }
        
                .std-dev {
                    font-size: 11px;
                    color: #64748b;
                }
        
                .caption {
                    margin-top: 20px;
                    font-style: italic;
                    color: #64748b;
                    font-size: 14px;
                    text-align: center;
                    font-weight: 500;
                    line-height: 1.5;
                }
        
                @media (max-width: 768px) {
                    .container {
                        padding: 20px;
                        margin: 10px;
                    }
                    
                    table {
                        font-size: 12px;
                    }
                    
                    th, td {
                        padding: 8px 12px;
                    }
                    
                    .table-title {
                        font-size: 24px;
                    }
                }
            </style>

            <div class="table-container" style="margin-top: 30px;">
                <div style="background: white; padding: 20px; border-radius: 12px;">
                    <p style="margin: 0 0 10px 0; font-weight: 600; color: #4a6cf7; font-size: 15px; text-transform: uppercase; letter-spacing: 0.5px;">References:</p>
                    <ol style="padding-left: 20px; margin: 0; font-size: 14px; line-height: 1.6;">
                        <li style="margin-bottom: 10px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. In <em>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015</em> (pp. 234–241). Springer. <a href="https://doi.org/10.1007/s11063-023-11333-x" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 10px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Oktay, O., Schlemper, J., Folgoc, L. L., Lee, M., Heinrich, M., Misawa, K., ... & Rueckert, D. (2018). Attention U-Net: Learning Where to Look for the Pancreas. <em>arXiv preprint arXiv:1804.03999</em>. <a href="https://doi.org/10.1007/s11063-023-11333-x" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 10px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Milletari, F., Navab, N., & Ahmadi, S. (2016). V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation. In <em>2016 Fourth International Conference on 3D Vision (3DV)</em> (pp. 565-571). IEEE. <a href="https://doi.org/10.1109/3DV.2016.79" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 0; text-align: left; padding: 8px 0 0 0;">Dar, M. F., & Ganivada, A. (2023). UMA-Net: A Novel Deep Learning Approach for Enhanced Breast Tumor Segmentation in Ultrasound Images. <em>Neural Processing Letters</em>. <a href="https://doi.org/10.1007/s11063-023-11333-x" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                    </ol>
                </div>
            </div>
        </div>

        <!-- Slide 14: UMA-Net Qualitative Comparison -->
        <div class="slide">
            <h2>UMA-Net: Qualitative Comparison</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/UMA-Net/Comp with other models.png" alt="Qualitative Comparison" style="width: 100%; border-radius: 8px;">
                <p class="caption">Qualitative comparison of segmentation results with different models on five publicly available datasets (BUSI, UDIAT, BUET, OMI, and Mendeley). Red contours: ground truth, Green contours: predicted segmentation</p>
            </div>
        </div>

        <!-- Slide 15: UMA-Net Loss Function Comparison -->
        <div class="slide">
            <h2>UMA-Net: Loss Function Ablation</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/UMA-Net/Comp_with other loss.png" alt="Loss Function Comparison" style="width: 100%; border-radius: 8px;">
                <p class="caption">Qualitative comparison of segmentation results with different loss functions on five publicly available datasets. Red contours: ground truth, Green contours: predicted segmentation</p>
            </div>
        </div>

        <!-- Slide 16: UMA-Net Statistical Significance -->
        <div class="slide">
            <h2>UMA-Net: Statistical Significance</h2>
            <div class="table-container" style="max-width: 95%; margin: 20px auto 0;">
                <table>
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>BUSI<sup>1</sup></th>
                            <th>UDIAT<sup>2</sup></th>
                            <th>BUET<sup>3</sup></th>
                            <th>OMI<sup>4</sup></th>
                            <th>Mendeley<sup>5</sup></th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="model-name">U-Net</td>
                            <td>8.25e-03</td>
                            <td>4.10e-02</td>
                            <td>1.55e-02</td>
                            <td>1.14e-02</td>
                            <td>4.82e-02</td>
                        </tr>
                        <tr>
                            <td class="model-name">Attention U-Net</td>
                            <td>6.56e-03</td>
                            <td>3.35e-02</td>
                            <td>1.80e-02</td>
                            <td>3.70e-02</td>
                            <td>4.27e-02</td>
                        </tr>
                        <tr>
                            <td class="model-name">V-Net</td>
                            <td>2.84e-02</td>
                            <td>4.44e-02</td>
                            <td>2.49e-02</td>
                            <td>4.27e-02</td>
                            <td>3.14e-02</td>
                        </tr>
                        <tr>
                            <td class="model-name">U-Net++</td>
                            <td>3.57e-02</td>
                            <td>1.29e-02</td>
                            <td>3.18e-02</td>
                            <td>1.50e-02</td>
                            <td>4.57e-02</td>
                        </tr>
                        <tr class="highlight-row">
                            <td class="model-name">ResUNet</td>
                            <td>4.56e-02</td>
                            <td>2.42e-02</td>
                            <td>2.21e-02</td>
                            <td>2.42e-02</td>
                            <td>1.40e-02</td>
                        </tr>
                    </tbody>
                </table>
                <p class="table-caption">Statistical significance (p-values) of paired t-tests comparing the Dice scores of UMA-Net models trained with the ensemble loss against UNet, VNet, Attention UNet, U-Net++, and ResUNet across five datasets (BUSI, UDIAT, BUET, OMI, and Mendeley).</p>
                <div style="background: white; padding: 20px; border-radius: 12px;">
                    <p style="margin: 0 0 15px 0; font-weight: 600; color: #4a6cf7; font-size: 16px; text-transform: uppercase; letter-spacing: 0.5px;">Dataset References:</p>
                    <ol start="1" style="padding-left: 20px; margin: 0; font-size: 14px; line-height: 1.6; list-style-type: decimal;">
                        <li style="margin-bottom: 12px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Al-Dhabyani, W., Gomaa, M., Khaled, H., & Fahmy, A. (2020). Dataset of breast ultrasound images. <em>Data in Brief, 28</em>, 104863. <a href="https://doi.org/10.1016/j.dib.2019.104863" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 12px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Yap, M. H., Pons, G., Martí, J., Ganau, S., Sentís, M., Zwiggelaar, R., Davison, A. K., & Martí, R. (2018). Automated Breast Ultrasound Lesions Detection Using Convolutional Neural Networks. <em>IEEE Journal of Biomedical and Health Informatics, 22</em>(4), 1218-1226. <a href="https://doi.org/10.1109/JBHI.2017.2731873" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 12px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Rodtook, A., Kirimasthong, K., Lohitvisate, W., & Makhanov, S. S. (2018). Automatic initialization of active contours and level set method in ultrasound images of breast abnormalities. <em>Pattern Recognition, 79</em>, 172-182. <a href="https://doi.org/10.1016/j.patcog.2018.01.032" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 12px; text-align: left; padding: 8px 0; border-bottom: 1px solid #f0f0f0;">Tasnim, J., & Hasan, M. K. (2023). CAM-QUS guided self-tuning modular CNNs with multi-loss functions for fully automated breast lesion classification in ultrasound images. <em>Physics in Medicine and Biology, 69</em>(1), 015018. <a href="https://doi.org/10.1088/1361-6560/ad1319" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                        <li style="margin-bottom: 0; text-align: left; padding: 8px 0 0 0;">Rodrigues, P. S. (2017). Breast Ultrasound Image. <em>Mendeley Data, V1</em>. <a href="https://doi.org/10.17632/wmy84gzngw.1" style="color: #4a6cf7; text-decoration: none; font-weight: 500;">DOI</a></li>
                    </ol>
                </div>
            </div>
            <style>
                .highlight-row {
                    background-color: #f0f7ff;
                }
                .highlight-row td {
                    font-weight: 500;
                }
                .table-container table {
                    font-size: 14px;
                }
                .table-container th, .table-container td {
                    padding: 10px 12px;
                    text-align: center;
                }
                .model-name {
                    text-align: left;
                    font-weight: 500;
                    white-space: nowrap;
                }
                .table-caption {
                    margin-top: 15px;
                    font-size: 14px;
                    color: #4a5568;
                    text-align: center;
                    font-style: italic;
                }
                @media (max-width: 768px) {
                    .table-container {
                        font-size: 12px;
                    }
                    .table-container th, .table-container td {
                        padding: 8px 10px;
                    }
                }
            </style>
            
        </div>

        <!-- Slide 17: FRS Loss Function -->
        <div class="slide">
            <h2>Fuzzy Rough Set (FRS) Loss Function</h2>
            <div class="highlight-box">
                <h3>Innovation</h3>
                <p>Novel loss function leveraging fuzzy rough set theory to handle boundary uncertainties and ambiguous regions in medical images.</p>
            </div>
            
            <div class="two-column">
                <div>
                    <h3>Fuzzy Set Component</h3>
                    <ul>
                        <li>Class mean and variance calculation</li>
                        <li>Fuzzy similarity distance computation</li>
                        <li>Membership value assignment</li>
                        <li>Influence value modulation</li>
                    </ul>
                </div>
                <div>
                    <h3>Rough Set Component</h3>
                    <ul>
                        <li>Lower approximation analysis</li>
                        <li>Upper approximation analysis</li>
                        <li>Weighted membership calculations</li>
                        <li>Uncertainty-sensitive penalties</li>
                    </ul>
                </div>
            </div>
            
            <div class="impact-stats">
                <h3>Results</h3>
                <p>Comprehensive experiments across breast ultrasound, gastrointestinal polyp, brain MRI, chest CT, and skin cancer imaging tasks demonstrated improved segmentation accuracy and reduced computational complexity.</p>
            </div>
        </div>

        <!-- Slide 18: FRS Loss Workflow -->
        <div class="slide">
            <h2>FRS Loss: Workflow Overview</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Model_Figures/FRS-Loss/FRS Loss WorkFlow.png" alt="FRS Loss Workflow" style="width: 100%; border-radius: 8px;">
                <p class="caption">The FRS loss function workflow processes input medical images through a segmentation network. The loss function evaluates predictions by combining fuzzy similarity metrics (handling pixel-wise uncertainty) with rough set approximations (managing boundary ambiguity). The loss is backpropagated to update network weights, progressively improving segmentation accuracy.</p>
            </div>
        </div>

        <!-- Slide 19: FRS Loss Architecture -->
        <div class="slide">
            <h2>FRS Loss: Rough Set Approximation</h2>
            <div class="image-container" style="max-width: 80%; margin: 20px auto 0;">
                <img src="Model_Figures/FRS-Loss/Rough Set.png" alt="Rough Set Approximation" style="width: 100%; border-radius: 8px;">
                <p class="caption">Visualization of the rough set approximation component. The figure illustrates how the FRS loss processes an input image through the rough set approximation module, handling boundary ambiguity in medical image segmentation.</p>
            </div>
        </div>

        <!-- Slide 20: FRS Loss Performance -->
        <div class="slide">
            <h2>FRS Loss: Performance Analysis</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/FRS-Loss/FRS Loss.png" alt="FRS Loss Performance" style="width: 100%; border-radius: 8px;">
                <p class="caption">Detailed convergence analysis of the proposed FRS loss function across five-fold cross-validation. The plot shows
                    individual fold trajectories, mean convergence (black line), and ±1 standard deviation band (gray area), with a final loss
                    value of 0.0146 ±0.0006.</p>
            </div>
        </div>

        <!-- Slide 21: FRS Loss Curves Comparison -->
        <div class="slide">
            <h2>FRS Loss: Training Dynamics</h2>
            <div class="image-container" style="max-width: 85%; margin: 20px auto 0;">
                <img src="Results/FRS-Loss/loss_curves.png" alt="Loss Curves Comparison" style="width: 100%; border-radius: 8px;">
                <p class="caption">Comparison of mean loss curves with 95% confidence intervals for different loss functions over 100 epochs of training. The curves demonstrate the distinct convergence patterns and final performance of each loss function.</p>
            </div>
        </div>

        <!-- Slide 22: FRS Loss Ablation Study -->
        <div class="slide">
            <h2>FRS Loss: Ablation Study</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/FRS-Loss/Ablation_FRS.png" alt="Ablation Study" style="width: 100%; border-radius: 8px;">
                <p class="caption">Quantitative ablation study of FRS loss components on the BUSI dataset. The complete FRS loss achieves the
                    best performance across all metrics.</p>
            </div>
        </div>

        <!-- Slide 23: FRS Loss Alpha Parameter Analysis -->
        <div class="slide">
            <h2>FRS Loss: Alpha Parameter Analysis</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/FRS-Loss/alpha_ablation_frs.png" alt="Alpha Parameter Analysis" style="width: 100%; border-radius: 8px;">
                <p class="caption"> Impact of weighting factor (α) on different performance metrics with U-Net on the BUSI dataset. The plot shows
                    the variation in Dice score, IoU, HD95, ASD, and BF-score across different values of (α) (0.1 to 0.9).</p>
            </div>
        </div>

        <!-- Slide 24: FRS Loss Computational Analysis -->
        <div class="slide">
            <h2>FRS Loss: Computational Efficiency</h2>
            <div style="margin-bottom: 30px;">
                <img src="Results/FRS-Loss/combined_computational_analysis.png" alt="Computational Efficiency Analysis" style="width: 100%; border-radius: 8px; margin-bottom: 10px;">
                <p class="caption">Computational efficiency analysis of FRS loss across different batch sizes. Left: Inference time comparison showing FRS loss performance on five medical imaging datasets (Chest CT, Kvasir Seg, BUSI, HAM10000, and Brain MRI) with batch sizes from 1 to 32. Right: Throughput analysis demonstrating processing capacity in images per second across the same datasets and batch size range.</p>
            </div>
            <div>
                <img src="Results/FRS-Loss/computational_analysis_results.png" alt="Comparative Computational Performance" style="width: 100%; border-radius: 8px;">
                <p class="caption">Comparative computational performance analysis of FRS loss against eight alternative loss functions. Top: Inference time comparison with error bars showing variance. Middle: Memory usage requirements in megabytes. Bottom: Training time per epoch in seconds. FRS loss demonstrates balanced performance across all three metrics.</p>
            </div>
        </div>

        <!-- Slide 25: SGAN -->
        <div class="slide">
            <h2>Saliency-Guided AttentionNet (SGAN)</h2>
            <div class="highlight-box">
                <h3>Challenge</h3>
                <p>High inter-class similarity and intra-class variation between benign and malignant breast lesions in ultrasound images.</p>
            </div>
            
            <div class="research-timeline">
                <div class="timeline-item">
                    <div class="timeline-number">1</div>
                    <div>
                        <h4>Dual-Branch Architecture</h4>
                        <p>Explicit decomposition of foreground (lesion) and background (peritumoral) features using shared MobileNet backbone</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-number">2</div>
                    <div>
                        <h4>Grad-CAM Saliency Guidance</h4>
                        <p>Precomputed saliency maps guide feature extraction without architectural modifications</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-number">3</div>
                    <div>
                        <h4>Adaptive Attention Fusion</h4>
                        <p>Dynamic channel-wise attention module fuses complementary feature streams</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 26: SGAN Architecture -->
        <div class="slide">
            <h2>SGAM: Architecture Overview</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Model_Figures/SGAN/Overall Model Architecture.png" alt="SGAN Architecture" style="width: 100%; border-radius: 8px;">
                <p class="caption">Proposed architecture of Saliency-Guided AttentionNet (SGAN) for medical image classification.</p>
            </div>
        </div>

        <!-- Slide 27: SGAN Classification Results -->
        <div class="slide">
            <h2>SGAN: Classification Performance</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/SGAN/Table-1.png" alt="SGAN Classification Results" style="width: 100%; border-radius: 8px;">
                <p class="caption">Comparison of breast lesion classification results (mean ± standard deviation) of SGAN with five CNN pre-trained models on five BUS image datasets using five-fold cross-validation.</p>
            </div>
        </div>

        <!-- Slide 28: SGAN Ablation Study -->
        <div class="slide">
            <h2>SGAN: Ablation Study & Feature Visualization</h2>
            <div style="margin-bottom: 25px;">
                <img src="Results/SGAN/Table-2.png" alt="SGAN Ablation Study" style="width: 100%; border-radius: 8px;">
                <p class="caption">Ablation study results on the BUSI dataset using five-fold cross-validation (mean ± standard deviation).</p>
            </div>
            <div>
                <img src="Results/SGAN/t-SNE visualization.png" alt="t-SNE Visualization" style="width: 100%; border-radius: 8px;">
                <p class="caption">t-SNE visualization of features extracted by SGAN, demonstrating reduced inter-class similarity and intra-class variation.</p>
            </div>
        </div>

        <!-- Slide 29: SGAN Computational Efficiency -->
        <div class="slide">
            <h2>SGAN: Computational Analysis</h2>
            <div style="margin-bottom: 25px;">
                <img src="Results/SGAN/Computational efficiency comparison.png" alt="Computational Efficiency" style="width: 100%; border-radius: 8px;">
                <p class="caption">Computational efficiency comparison of SGAN with baseline models on the BUSI dataset.</p>
            </div>
            <div>
                <img src="Results/SGAN/Comparison of SGAN results.png" alt="Comparison with Existing Methods" style="width: 100%; border-radius: 8px;">
                <p class="caption">Comparison of SGAN results with other existing methods on four datasets. MobileNet serves as the backbone network for SGAN.</p>
            </div>
        </div>

        <!-- Slide 30: SGAN Grad-CAM Visualization -->
        <div class="slide">
            <h2>SGAN: Attention Map Visualization</h2>
            <div class="image-container" style="max-width: 90%; margin: 20px auto 0;">
                <img src="Results/SGAN/Grad CAM results comparision.png" alt="Grad-CAM Visualizations" style="width: 100%; border-radius: 8px;">
                <p class="caption">Grad-CAM visualizations comparing attention maps across five BUS datasets (BUET, BUSI, Mendeley, OMI, and UDIAT). Each row represents a different dataset, with columns showing the original ultrasound image (leftmost) and corresponding attention maps from DenseNet121, InceptionV3, MobileNetV2, ResNet101V2, Xception, and SGAN (rightmost). Heatmaps highlight regions influencing predictions, with warmer colors indicating higher importance.</p>
            </div>
        </div>

        <!-- Slide 31: Conclusions & Future Work -->
        <div class="slide">
            <h2>Conclusions & Future Directions</h2>
            <div class="two-column">
                <div>
                    <h3>Key Contributions</h3>
                    <ul>
                        <li>Five novel architectures addressing critical medical imaging challenges</li>
                        <li>Balanced efficiency and accuracy for clinical deployment</li>
                        <li>State-of-the-art performance across multiple datasets</li>
                        <li>Innovative loss function design with fuzzy rough set theory</li>
                        <li>Interpretable AI through saliency-guided attention</li>
                    </ul>
                    <h3>Research Impact</h3>
                    <p style="text-align: center; font-size: 1.4rem;">
                        <strong>Bridging the gap between advanced AI research and practical clinical applications</strong><br>
                        through computationally efficient, accurate, and interpretable deep learning solutions
                    </p>
                </div>
                <div>
                    <h3>Future Research Directions</h3>
                    <ul>
                        <li>Develop hybrid fusion architectures for <strong>multi-modal segmentation</strong> across MRI, PET/CT, and ultrasound</li>
                        <li>Advance <strong>multi-view segmentation</strong> techniques for improved diagnostic accuracy</li>
                        <li>Innovate in <strong>self-supervised learning</strong> with contrastive pixel-level pretraining</li>
                        <li>Enhance <strong>few-shot learning</strong> approaches to minimize annotation requirements</li>
                        <li>Implement <strong>masked autoencoding</strong> strategies for robust feature learning</li>
                        <li>Address challenges in <strong>medical AI deployment</strong> through efficient learning paradigms</li>
                    </ul>
                </div>
            </div>
            
            <div class="author-info">
                <p style="font-size: 1.6rem; color: #667eea;"><strong>Thank you for your attention</strong></p>
                <p>Questions & Discussion</p>
            </div>
        </div>

        <!-- Slide 32: Published Work -->
        <div class="slide">
            <h2>Published Work</h2>
            <div class="publications-container">
                <div class="publication">
                    <div class="pub-number">1</div>
                    <div class="pub-content">
                        <div class="pub-title">Adaptive ensemble loss and multi-scale attention in breast ultrasound segmentation with UMA-Net</div>
                        <div class="pub-authors">Dar, M.F. & Ganivada, A.</div>
                        <div class="pub-journal">Medical & Biological Engineering & Computing (2025) <span class="index-badge sci">SCI Indexed with Impact Factor: 2.6</span></div>
                        <div class="pub-doi">doi: 10.1007/s11517-025-03301-5</div>
                    </div>
                </div>
                
                <div class="publication">
                    <div class="pub-number">2</div>
                    <div class="pub-content">
                        <div class="pub-title">Deep learning and genetic algorithm-based ensemble model for feature selection and classification of breast ultrasound images</div>
                        <div class="pub-authors">Dar, M.F. & Ganivada, A.</div>
                        <div class="pub-journal">Image and Vision Computing, 146, 105018 (2024) <span class="index-badge sci">SCI Indexed with Impact Factor: 4.2</span></div>
                        <div class="pub-doi">doi: 10.1016/J.IMAVIS.2024.105018</div>
                    </div>
                </div>
                
                <div class="publication">
                    <div class="pub-number">3</div>
                    <div class="pub-content">
                        <div class="pub-title">EfficientU-Net: A Novel Deep Learning Method for Breast Tumor Segmentation and Classification in Ultrasound Images</div>
                        <div class="pub-authors">Dar, M.F. & Ganivada, A.</div>
                        <div class="pub-journal">Neural Processing Letters, 55, 10439-10462 (2023) <span class="index-badge sci">SCI Indexed with Impact Factor: 2.8</span></div>
                        <div class="pub-doi">doi: 10.1007/s11063-023-11333-x</div>
                    </div>
                </div>
                
                <div class="publication">
                    <div class="pub-number">4</div>
                    <div class="pub-content">
                        <div class="pub-title">Dynamic Weight-Adjusted Ensemble Loss for Enhanced Medical Image Segmentation</div>
                        <div class="pub-authors">Dar, M.F. & Ganivada, A.</div>
                        <div class="pub-journal">In: Kumar, A. et al. (eds) Proceedings of Fourth International Conference on Computing and Communication Networks. ICCCN 2024. Springer, Singapore (2025) <span class="index-badge scopus">Scopus Indexed</span></div>
                        <div class="pub-doi">doi: 10.1007/978-981-96-3250-3_1</div>
                    </div>
                </div>
                
                <div class="publication">
                    <div class="pub-number">5</div>
                    <div class="pub-content">
                        <div class="pub-title">Design and analysis of a robust security layer for software defined network framework</div>
                        <div class="pub-authors">Alhaj, A.N., Patel, N.D., Singh, A., Bondugula, R.K., Dar, M.F. & Ahamed, J.</div>
                        <div class="pub-journal">International Journal of Sensor Networks, 46(1), 1-14 (2024) <span class="index-badge scopus">Scopus Indexed</span></div>
                        <div class="pub-doi">doi: 10.1504/IJSNET.2024.141613</div>
                    </div>
                </div>
                
                <div class="publication">
                    <div class="pub-number">6</div>
                    <div class="pub-content">
                        <div class="pub-title">Latent fingerprint enhancement and matching using intuitionistic type-2 fuzzy</div>
                        <div class="pub-authors">Mukhtar, S., Dar, M.F. & Kaur, A.</div>
                        <div class="pub-journal">International Journal of Artificial Intelligence and Soft Computing, 7(4), 313-328 (2022) <span class="index-badge scopus">Scopus Indexed</span></div>
                        <div class="pub-doi">doi: 10.1504/IJAISC.2022.130558</div>
                    </div>
                </div>
                
                <div class="publication">
                    <div class="pub-number">7</div>
                    <div class="pub-content">
                        <div class="pub-title">Performance Comparison of Face Detection and Recognition Algorithms</div>
                        <div class="pub-authors">Dar, M.F. & Dixit, S.</div>
                        <div class="pub-journal">International Journal of Science and Research (IJSR), 8(1), 986-994 (2019) <span class="index-badge other">EuroPub, CrossRef</span></div>
                        <div class="pub-doi">doi: 10.21275/ART20194439</div>
                    </div>
                </div>
            </div>
            
            <style>
                .publications-container {
                    width: 100%;
                    max-width: 1200px;
                    margin: 0 auto;
                    max-height: 70vh;
                    overflow-y: auto;
                    padding: 10px;
                }
                
                .publication {
                    display: flex;
                    margin-bottom: 20px;
                    padding: 15px;
                    background-color: #f8f9ff;
                    border-radius: 8px;
                    border-left: 4px solid #667eea;
                    transition: transform 0.3s ease, box-shadow 0.3s ease;
                }
                
                .publication:hover {
                    transform: translateY(-3px);
                    box-shadow: 0 5px 15px rgba(0,0,0,0.1);
                }
                
                .pub-number {
                    font-size: 1.5rem;
                    font-weight: bold;
                    color: #764ba2;
                    min-width: 40px;
                    margin-right: 15px;
                    display: flex;
                    align-items: flex-start;
                    padding-top: 3px;
                }
                
                .pub-content {
                    flex: 1;
                }
                
                .pub-title {
                    font-weight: 600;
                    color: #2c3e50;
                    margin-bottom: 5px;
                    line-height: 1.3;
                }
                
                .pub-authors {
                    font-style: italic;
                    color: #555;
                    margin-bottom: 3px;
                    font-size: 0.95rem;
                }
                
                .pub-journal {
                    color: #444;
                    margin-bottom: 3px;
                    font-size: 0.9rem;
                }
                
                .pub-doi {
                    color: #667eea;
                    font-size: 0.85rem;
                    word-break: break-all;
                }
                
                .index-badge {
                    display: inline-block;
                    padding: 2px 8px;
                    border-radius: 10px;
                    font-size: 0.65rem;
                    font-weight: 600;
                    margin-left: 8px;
                    vertical-align: middle;
                    color: white;
                    white-space: nowrap;
                }
                
                .sci {
                    background-color: #e74c3c; /* Red for SCI */
                }
                
                .scopus {
                    background-color: #e67e22; /* Orange for Scopus */
                }
                
                .other {
                    background-color: #7f8c8d; /* Gray for other indices */
                }
                
                /* Scrollbar styling */
                .publications-container::-webkit-scrollbar {
                    width: 8px;
                }
                
                .publications-container::-webkit-scrollbar-track {
                    background: #f1f1f1;
                    border-radius: 10px;
                }
                
                .publications-container::-webkit-scrollbar-thumb {
                    background: #a5a9b8;
                    border-radius: 10px;
                }
                
                .publications-container::-webkit-scrollbar-thumb:hover {
                    background: #667eea;
                }
            </style>
        </div>
    </div>

        <!-- Slide 33: Teaching Expertise -->
        <div class="slide">
            <h2>Teaching Experience</h2>
            
            <div class="teaching-container">
                <div class="teaching-institution">
                    <h3>Govt Degree College, Uri</h3>
                    <div class="teaching-role">Assistant Professor</div>
                    <ul class="teaching-courses">
                        <li>Discrete Mathematics</li>
                        <li>Data Structures and Algorithms</li>
                    </ul>
                </div>
                
                <div class="teaching-institution" style="margin-top: 40px;">
                    <h3>University of Hyderabad</h3>
                    <div class="teaching-role">Teaching Assistant (PhD)</div>
                    <ul class="teaching-courses">
                        <li>Discrete Mathematics</li>
                        <li>Data Structures</li>
                        <li>Research Methodology</li>
                        <li>Deep Learning</li>
                    </ul>
                </div>
            </div>
            
            <style>
                .teaching-container {
                    width: 100%;
                    max-width: 900px;
                    margin: 30px auto 0;
                    text-align: left;
                }
                
                .teaching-institution {
                    background: #f8f9ff;
                    padding: 25px 30px;
                    border-radius: 10px;
                    margin-bottom: 20px;
                    box-shadow: 0 4px 15px rgba(0,0,0,0.05);
                    border-left: 5px solid #667eea;
                }
                
                .teaching-institution h3 {
                    color: #2c3e50;
                    margin: 0 0 5px 0;
                    font-size: 1.5rem;
                    border-bottom: none;
                    text-align: left;
                    padding: 0;
                }
                
                .teaching-role {
                    color: #6c757d;
                    font-style: italic;
                    margin-bottom: 15px;
                    font-size: 1rem;
                }
                
                .teaching-courses {
                    list-style-type: none;
                    padding: 0;
                    margin: 0;
                }
                
                .teaching-courses li {
                    padding: 8px 0 8px 30px;
                    position: relative;
                    font-size: 1.1rem;
                    color: #333;
                    border-bottom: 1px solid #eee;
                }
                
                .teaching-courses li:last-child {
                    border-bottom: none;
                }
                
                .teaching-courses li:before {
                    content: "•";
                    color: #667eea;
                    font-weight: bold;
                    font-size: 1.5rem;
                    position: absolute;
                    left: 10px;
                    top: 2px;
                }
                
                .author-info {
                    margin-top: 50px;
                    text-align: center;
                    padding: 20px;
                    background: rgba(255, 255, 255, 0.1);
                    border-radius: 10px;
                    max-width: 600px;
                    margin-left: auto;
                    margin-right: auto;
                }
                
                .author-info p {
                    margin: 10px 0;
                    color: #2c3e50;
                }
            </style>
            
            <div class="author-info">
                <p style="font-size: 1.6rem; color: #667eea;"><strong>Thank you for your attention</strong></p>
                <p>Questions & Discussion</p>
            </div>
        </div>

        

    <div class="navigation">
        <button class="nav-btn" id="prevBtn" title="Previous Slide (← or ↑)">← Previous</button>
        <div id="slideCounter" style="color: #666; font-weight: 500;">1 / 1</div>
        <button class="nav-btn" id="nextBtn" title="Next Slide (→, ↓, or Space)">Next →</button>
    </div>

    <!-- Navigation Menu -->
    <div class="nav-menu" id="navMenu">
        <!-- Will be populated by JavaScript -->
    </div>

    <style>
        /* Navigation Menu */
        .nav-menu {
            position: fixed;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            background: rgba(255, 255, 255, 0.95);
            border-radius: 10px;
            padding: 15px 5px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            z-index: 1000;
            display: flex;
            flex-direction: column;
            gap: 8px;
            max-height: 80vh;
            overflow-y: auto;
            width: 200px;
        }

        .nav-item {
            padding: 8px 12px;
            border-radius: 6px;
            background-color: transparent;
            cursor: pointer;
            transition: all 0.2s ease;
            position: relative;
            border-left: 3px solid transparent;
            font-size: 0.85rem;
            color: #4a5568;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .nav-item:hover {
            background-color: #f0f4ff;
            color: #4a6cf7;
            transform: translateX(-2px);
        }

        .nav-item.active {
            background-color: #f0f4ff;
            color: #4a6cf7;
            border-left: 3px solid #4a6cf7;
            font-weight: 500;
            transform: none;
        }
        
        .nav-section {
            font-size: 0.75rem;
            font-weight: 600;
            color: #718096;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin: 10px 12px 4px;
            padding-bottom: 4px;
            border-bottom: 1px solid #e2e8f0;
        }

        .caption {
            font-size: 0.85rem;
            color: #666;
            text-align: center;
            margin: 5px 0 15px 0;
            line-height: 1.4;
            max-width: 100%;
            padding: 0 10px;
        }
        
        .highlight-box {
            background: #f8f9fa;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
            width: 100%;
            max-width: 1600px;
            box-sizing: border-box;
            overflow-y: auto;
            align-self: center;
        }
        
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }
    </style>
    
    <script>
        // Global variables
        let currentSlide = 0;
        let slides = [];
        let totalSlides = 0;
        let timerInterval;
        
        // Function to change slide
        function changeSlide(direction) {
            showSlide(currentSlide + direction);
        }
        
        // Function to show specific slide
        function showSlide(n) {
            // Hide current slide with transition
            const currentActive = document.querySelector('.slide.active');
            if (currentActive) {
                currentActive.classList.remove('active');
            }
            
            // Update current slide index
            currentSlide = (n + totalSlides) % totalSlides;
            
            // Show new slide with transition
            slides[currentSlide].classList.add('active');
            
            // Update slide counter
            const slideCounter = document.getElementById('slideCounter');
            const currentSlideNumber = document.getElementById('currentSlideNumber');
            if (slideCounter) {
                slideCounter.textContent = `${currentSlide + 1} / ${totalSlides}`;
            }

        // Update current slide index
        currentSlide = (n + totalSlides) % totalSlides;
        
        // Show new slide with transition
        slides[currentSlide].classList.add('active');
        
        // Update slide counter
        const slideCounterEl = document.getElementById('slideCounter');
        const currentSlideNumberEl = document.getElementById('currentSlideNumber');
        if (slideCounterEl) {
            slideCounterEl.textContent = `${currentSlide + 1} / ${totalSlides}`;
        }
        if (currentSlideNumberEl) {
            currentSlideNumberEl.textContent = currentSlide + 1;
        }
        
        // Update navigation buttons
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
        if (prevBtn) prevBtn.disabled = currentSlide === 0;
        if (nextBtn) nextBtn.disabled = currentSlide === totalSlides - 1;
        
        // Update navigation menu
        updateNavMenu();
    }
    
    // Define sections with their start slide index and title
    const sections = [
        { title: 'Research Overview', slideIndex: 2 },
        { title: 'EfficientU-Net', slideIndex: 3 },
        { title: 'UMA-Net', slideIndex: 8 },
        { title: 'FRS Loss', slideIndex: 16 },
        { title: 'SGAN', slideIndex: 24 },
        { title: 'Conclusions', slideIndex: 30 },
        { title: 'Published Work', slideIndex: 31 },
        { title: 'Teaching Experience', slideIndex: 32 }
    ];

    // Initialize navigation menu
    function initNavMenu() {
        const navMenu = document.getElementById('navMenu');
        if (!navMenu) return;
        
        // Clear existing items
        navMenu.innerHTML = '';
        
        // Add section header
        const header = document.createElement('div');
        header.className = 'nav-section';
        header.textContent = 'Sections';
        navMenu.appendChild(header);
        
        // Create navigation items for each section
        sections.forEach(section => {
            const navItem = document.createElement('div');
            navItem.className = 'nav-item';
            navItem.textContent = section.title;
            navItem.dataset.slide = section.slideIndex;
            navItem.addEventListener('click', () => showSlide(section.slideIndex));
            navMenu.appendChild(navItem);
        });
        
        // Initialize active state
        updateNavMenu();
    }
    
    // Update navigation menu active state
    function updateNavMenu() {
        const navMenu = document.getElementById('navMenu');
        if (currentSlide < 2) {
            navMenu.style.display = 'none';
        } else {
            navMenu.style.display = 'flex';
        }
        
        const navItems = document.querySelectorAll('.nav-item');
        
        // Find the current section
        let currentSectionIndex = 0;
        for (let i = sections.length - 1; i >= 0; i--) {
            if (currentSlide >= sections[i].slideIndex) {
                currentSectionIndex = i;
                break;
            }
        }
        
        // Update active state
        navItems.forEach((item, index) => {
            if (index === currentSectionIndex) {
                item.classList.add('active');
            } else {
                item.classList.remove('active');
            }
        });
    }
    
    // Initialize presentation
    document.addEventListener('DOMContentLoaded', function() {
        // Get all slides
        slides = document.querySelectorAll('.slide');
        totalSlides = slides.length;
        
        // Initialize timer
        let startTime = new Date();
        updateTimer(); // Initial call to display 00:00
        timerInterval = setInterval(updateTimer, 1000);
        
        // Make showSlide available globally
        window.showSlide = showSlide;
        
        // Initialize navigation menu
        initNavMenu();
        
        // Timer function
        function updateTimer() {
            const now = new Date();
            const diff = now - startTime;
            const minutes = Math.floor(diff / 60000);
            const seconds = Math.floor((diff % 60000) / 1000);
            const timerElement = document.getElementById('presentationTimer');
            if (timerElement) {
                timerElement.textContent = 
                    (minutes < 10 ? '0' : '') + minutes + ':' + 
                    (seconds < 10 ? '0' : '') + seconds;
            }
        }
        
        // Initialize first slide
        showSlide(0);
        
        // Clean up timer when leaving page
        window.addEventListener('beforeunload', () => {
            if (timerInterval) clearInterval(timerInterval);
        });
        
        // Add event listeners for navigation buttons
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
            
            if (prevBtn) prevBtn.addEventListener('click', () => changeSlide(-1));
            if (nextBtn) nextBtn.addEventListener('click', () => changeSlide(1));
            
            // Keyboard navigation
            document.addEventListener('keydown', function(e) {
                switch(e.key) {
                    case 'ArrowLeft':
                        changeSlide(-1);
                        break;
                    case 'ArrowRight':
                    case ' ':
                        changeSlide(1);
                        break;
                }
            });
        });

        // Keyboard navigation
        document.addEventListener('keydown', function(event) {
            if (event.key === 'ArrowRight' || event.key === ' ') {
                changeSlide(1);
            } else if (event.key === 'ArrowLeft') {
                changeSlide(-1);
            }
        });

        // Make showSlide globally accessible
        window.showSlide = showSlide;
        
        // Initialize
        showSlide(0);

        // Remove auto-advance for actual presentation
        // setInterval(() => changeSlide(1), 10000);
    </script>
</body>
</html>
